{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16 viz Filters\n",
    "\n",
    "#### author info\n",
    "* by Aven Le ZHOU (https://www.aven.cc)\n",
    "* artMahcines & NYU Shanghai\n",
    "* aiarts, spring 2020\n",
    "* https://github.com/artmachines/aiarts2020\n",
    "\n",
    "#### credits\n",
    "* Original code implementation from keras team [link](https://keras.io/examples/conv_filter_visualization/)\n",
    "* adapted by Aven for aiarts 2020 course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_plaidML_backend = True\n",
    "use_colab = False\n",
    "\n",
    "if use_plaidML_backend and (not use_colab): \n",
    "    import os\n",
    "    os.environ[\"KERAS_BACKEND\"]=\"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.applications import vgg16\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x): return (x / (K.sqrt(K.mean(K.square(x))) + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(x):\n",
    "    \"\"\"convert a float array into a valid uint8 image. x: A numpy-array representing the generated image.\"\"\"\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first': x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(x, former):\n",
    "    \"\"\"convert a valid uint8 image back into a float array. Reverses `decode_image`.\"\"\"\n",
    "    if K.image_data_format() == 'channels_first': x = x.transpose((2, 0, 1))\n",
    "    return (x / 255 - 0.5) * 4 * former.std() + former.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize_layer: visualizes the most relevant filters of one conv-layer in a certain model.\n",
    "* model: The model containing layer_name.\n",
    "* layer_name: The name of the layer to be visualized. Has to be a part of model.\n",
    "* step: step size for gradient ascent.\n",
    "* epochs: Number of iterations for gradient ascent.\n",
    "* upscaling_steps: Number of upscaling steps. Starting image is in this case (80, 80).\n",
    "* upscaling_factor: Factor to which to slowly upgrade the image towards output_dim.\n",
    "* output_dim: [img_width, img_height] The output image dimensions.\n",
    "* filter_range: Tupel[lower, upper]\n",
    "              Determines the to be computed filter numbers.\n",
    "              If the second value is `None`,\n",
    "              the last filter will be inferred as the upper boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_layer(model,\n",
    "                    layer_name,\n",
    "                    step=1.,\n",
    "                    epochs=15,\n",
    "                    upscaling_steps=9,\n",
    "                    upscaling_factor=1.2,\n",
    "                    output_dim=(412, 412),\n",
    "                    filter_range=(0, None)):\n",
    "\n",
    "\n",
    "    def _generate_filter_image(input_img,\n",
    "                               layer_output,\n",
    "                               filter_index):\n",
    "        \"\"\"\n",
    "            Generates image for one particular filter.\n",
    "            input_img: The input-image Tensor.\n",
    "            layer_output: The output-image Tensor.\n",
    "            filter_index: The to be processed filter number. Assumed to be valid.\n",
    "            Returns: a tuple of the image (array) itself and the last loss. or None if no image could be generated.\n",
    "        \"\"\"\n",
    "        s_time = time.time()\n",
    "\n",
    "        # we build a loss function that maximizes the activation of the nth filter of the layer considered\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "        else:\n",
    "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "        # we compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "        # normalization trick: we normalize the gradient\n",
    "        grads = normalize(grads)\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "        # we start from a gray image with some random noise\n",
    "        intermediate_dim = tuple(\n",
    "            int(x / (upscaling_factor ** upscaling_steps)) for x in output_dim)\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random(\n",
    "                (1, 3, intermediate_dim[0], intermediate_dim[1]))\n",
    "        else:\n",
    "            input_img_data = np.random.random(\n",
    "                (1, intermediate_dim[0], intermediate_dim[1], 3))\n",
    "        input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "        # Slowly upscaling towards the original size prevents\n",
    "        # a dominating high-frequency of the to visualized structure\n",
    "        # as it would occur if we directly compute the 412d-image.\n",
    "        # Behaves as a better starting point for each following dimension\n",
    "        # and therefore avoids poor local minima\n",
    "        for up in reversed(range(upscaling_steps)):\n",
    "            # we run gradient ascent for e.g. 20 steps\n",
    "            for _ in range(epochs):\n",
    "                loss_value, grads_value = iterate([input_img_data])\n",
    "                input_img_data += grads_value * step\n",
    "\n",
    "                # some filters get stuck to 0, we can skip them\n",
    "                if loss_value <= K.epsilon():\n",
    "                    return None\n",
    "\n",
    "            # Calculate upscaled dimension\n",
    "            intermediate_dim = tuple(\n",
    "                int(x / (upscaling_factor ** up)) for x in output_dim)\n",
    "            # Upscale\n",
    "            img = decode_image(input_img_data[0])\n",
    "            img = np.array(pil_image.fromarray(img).resize(intermediate_dim,\n",
    "                                                           pil_image.BICUBIC))\n",
    "            input_img_data = np.expand_dims(\n",
    "                encode_image(img, input_img_data[0]), 0)\n",
    "\n",
    "        # decode the resulting input image\n",
    "        img = decode_image(input_img_data[0])\n",
    "        e_time = time.time()\n",
    "        print('Costs of filter {:3}: {:5.0f} ( {:4.2f}s )'.format(filter_index,\n",
    "                                                                  loss_value,\n",
    "                                                                  e_time - s_time))\n",
    "        return img, loss_value\n",
    "\n",
    "    def _draw_filters(filters, n=None):\n",
    "        \"\"\"Draw the best filters in a nxn grid.\n",
    "\n",
    "        # Arguments\n",
    "            filters: A List of generated images and their corresponding losses\n",
    "                     for each processed filter.\n",
    "            n: dimension of the grid.\n",
    "               If none, the largest possible square will be used\n",
    "        \"\"\"\n",
    "        if n is None:\n",
    "            n = int(np.floor(np.sqrt(len(filters))))\n",
    "\n",
    "        # the filters that have the highest loss are assumed to be better-looking.\n",
    "        # we will only keep the top n*n filters.\n",
    "        filters.sort(key=lambda x: x[1], reverse=True)\n",
    "        filters = filters[:n * n]\n",
    "\n",
    "        # build a black picture with enough space for\n",
    "        # e.g. our 8 x 8 filters of size 412 x 412, with a 5px margin in between\n",
    "        MARGIN = 5\n",
    "        width = n * output_dim[0] + (n - 1) * MARGIN\n",
    "        height = n * output_dim[1] + (n - 1) * MARGIN\n",
    "        stitched_filters = np.zeros((width, height, 3), dtype='uint8')\n",
    "\n",
    "        # fill the picture with our saved filters\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                img, _ = filters[i * n + j]\n",
    "                width_margin = (output_dim[0] + MARGIN) * i\n",
    "                height_margin = (output_dim[1] + MARGIN) * j\n",
    "                stitched_filters[\n",
    "                    width_margin: width_margin + output_dim[0],\n",
    "                    height_margin: height_margin + output_dim[1],\n",
    "                    :] = img\n",
    "\n",
    "        # save the result to disk\n",
    "        save_img('vgg_{0:}_{1:}x{1:}.png'.format(layer_name, n), stitched_filters)\n",
    "\n",
    "    # this is the placeholder for the input images\n",
    "    assert len(model.inputs) == 1\n",
    "    input_img = model.inputs[0]\n",
    "\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "    output_layer = layer_dict[layer_name]\n",
    "    assert isinstance(output_layer, layers.Conv2D)\n",
    "\n",
    "    # Compute to be processed filter range\n",
    "    filter_lower = filter_range[0]\n",
    "    filter_upper = (filter_range[1]\n",
    "                    if filter_range[1] is not None\n",
    "                    else len(output_layer.get_weights()[1]))\n",
    "    assert(filter_lower >= 0\n",
    "           and filter_upper <= len(output_layer.get_weights()[1])\n",
    "           and filter_upper > filter_lower)\n",
    "    print('Compute filters {:} to {:}'.format(filter_lower, filter_upper))\n",
    "\n",
    "    # iterate through each filter and generate its corresponding image\n",
    "    processed_filters = []\n",
    "    for f in range(filter_lower, filter_upper):\n",
    "        img_loss = _generate_filter_image(input_img, output_layer.output, f)\n",
    "\n",
    "        if img_loss is not None:\n",
    "            processed_filters.append(img_loss)\n",
    "\n",
    "    print('{} filter processed.'.format(len(processed_filters)))\n",
    "    # Finally draw and store the best filters to disk\n",
    "    _draw_filters(processed_filters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"metal_amd_radeon_pro_560x.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Compute filters 0 to 512\n",
      "Costs of filter   0:   406 ( 47.54s )\n",
      "Costs of filter   2:   423 ( 48.26s )\n",
      "Costs of filter   3:   502 ( 47.48s )\n",
      "Costs of filter   4:   587 ( 47.54s )\n",
      "Costs of filter   5:   512 ( 47.58s )\n",
      "Costs of filter   7:   931 ( 46.48s )\n",
      "Costs of filter   8:   860 ( 47.12s )\n",
      "Costs of filter   9:   477 ( 47.73s )\n",
      "Costs of filter  11:   770 ( 47.46s )\n",
      "Costs of filter  13:   340 ( 47.02s )\n",
      "Costs of filter  14:   689 ( 47.07s )\n",
      "Costs of filter  15:   523 ( 47.67s )\n",
      "Costs of filter  17:   854 ( 47.39s )\n",
      "Costs of filter  18:   665 ( 47.55s )\n",
      "Costs of filter  20:   534 ( 47.65s )\n",
      "Costs of filter  23:   523 ( 46.82s )\n",
      "Costs of filter  24:   443 ( 48.22s )\n",
      "Costs of filter  25:   564 ( 47.86s )\n",
      "Costs of filter  27:   907 ( 48.40s )\n",
      "Costs of filter  28:   548 ( 47.85s )\n",
      "Costs of filter  29:   545 ( 48.11s )\n",
      "Costs of filter  30:   586 ( 48.17s )\n",
      "Costs of filter  31:   411 ( 48.30s )\n",
      "Costs of filter  32:   374 ( 48.14s )\n",
      "Costs of filter  33:   901 ( 48.04s )\n",
      "Costs of filter  34:   499 ( 48.09s )\n",
      "Costs of filter  36:   872 ( 47.11s )\n",
      "Costs of filter  37:   797 ( 47.82s )\n",
      "Costs of filter  38:   422 ( 47.42s )\n",
      "Costs of filter  40:   849 ( 47.38s )\n",
      "Costs of filter  42:   849 ( 47.55s )\n",
      "Costs of filter  43:   406 ( 47.07s )\n",
      "Costs of filter  44:   597 ( 47.27s )\n",
      "Costs of filter  47:   694 ( 47.38s )\n",
      "Costs of filter  48:   691 ( 47.72s )\n",
      "Costs of filter  49:   829 ( 47.42s )\n",
      "Costs of filter  51:   468 ( 47.75s )\n",
      "Costs of filter  53:   694 ( 47.71s )\n",
      "Costs of filter  55:   410 ( 47.78s )\n",
      "Costs of filter  58:   358 ( 47.92s )\n",
      "Costs of filter  59:   904 ( 47.69s )\n",
      "Costs of filter  61:   924 ( 47.86s )\n",
      "Costs of filter  62:   636 ( 48.14s )\n",
      "Costs of filter  63:  1122 ( 46.57s )\n",
      "Costs of filter  64:  1183 ( 45.78s )\n",
      "Costs of filter  65:   255 ( 45.88s )\n",
      "Costs of filter  68:   829 ( 47.23s )\n",
      "Costs of filter  70:   588 ( 47.78s )\n",
      "Costs of filter  73:   712 ( 47.42s )\n",
      "Costs of filter  74:   484 ( 47.01s )\n",
      "Costs of filter  75:   306 ( 47.59s )\n",
      "Costs of filter  76:   880 ( 47.67s )\n",
      "Costs of filter  79:   803 ( 46.92s )\n",
      "Costs of filter  80:   443 ( 47.04s )\n",
      "Costs of filter  81:   465 ( 48.53s )\n",
      "Costs of filter  82:   635 ( 48.11s )\n",
      "Costs of filter  84:   525 ( 47.67s )\n",
      "Costs of filter  86:  1019 ( 50.67s )\n",
      "Costs of filter  87:   773 ( 50.16s )\n",
      "Costs of filter  88:   941 ( 49.72s )\n",
      "Costs of filter  91:   662 ( 49.95s )\n",
      "Costs of filter  92:   451 ( 49.29s )\n",
      "Costs of filter  97:   431 ( 49.55s )\n",
      "Costs of filter  99:   479 ( 49.98s )\n",
      "Costs of filter 101:   333 ( 48.98s )\n",
      "Costs of filter 102:   899 ( 48.96s )\n",
      "Costs of filter 110:   650 ( 48.03s )\n",
      "Costs of filter 112:   312 ( 48.64s )\n",
      "Costs of filter 113:   619 ( 48.35s )\n",
      "Costs of filter 114:   767 ( 48.51s )\n",
      "Costs of filter 115:   434 ( 49.19s )\n",
      "Costs of filter 119:   861 ( 49.18s )\n",
      "Costs of filter 121:   436 ( 49.17s )\n",
      "Costs of filter 123:   455 ( 48.21s )\n",
      "Costs of filter 124:   367 ( 48.13s )\n",
      "Costs of filter 126:   960 ( 49.32s )\n",
      "Costs of filter 127:   422 ( 49.24s )\n",
      "Costs of filter 128:   825 ( 48.04s )\n",
      "Costs of filter 131:   564 ( 48.06s )\n",
      "Costs of filter 132:   340 ( 47.91s )\n",
      "Costs of filter 133:   516 ( 47.94s )\n",
      "Costs of filter 135:   416 ( 47.83s )\n",
      "Costs of filter 136:   725 ( 48.08s )\n",
      "Costs of filter 137:   434 ( 47.16s )\n",
      "Costs of filter 138:  1341 ( 45.80s )\n",
      "Costs of filter 139:   395 ( 46.70s )\n",
      "Costs of filter 140:   529 ( 47.96s )\n",
      "Costs of filter 141:   580 ( 48.87s )\n",
      "Costs of filter 143:   838 ( 48.89s )\n",
      "Costs of filter 145:   487 ( 48.61s )\n",
      "Costs of filter 146:  1232 ( 49.42s )\n",
      "Costs of filter 149:   522 ( 47.33s )\n",
      "Costs of filter 151:   607 ( 50.24s )\n",
      "Costs of filter 152:   586 ( 47.00s )\n",
      "Costs of filter 154:   641 ( 47.16s )\n",
      "Costs of filter 155:   469 ( 48.24s )\n",
      "Costs of filter 157:   880 ( 48.19s )\n",
      "Costs of filter 158:   696 ( 48.17s )\n",
      "Costs of filter 161:   474 ( 48.30s )\n",
      "Costs of filter 162:   639 ( 48.92s )\n",
      "Costs of filter 163:   703 ( 48.65s )\n",
      "Costs of filter 165:   524 ( 47.20s )\n",
      "Costs of filter 166:   710 ( 47.79s )\n",
      "Costs of filter 167:   711 ( 50.03s )\n",
      "Costs of filter 168:   523 ( 49.92s )\n",
      "Costs of filter 170:   773 ( 49.30s )\n",
      "Costs of filter 171:   649 ( 49.38s )\n",
      "Costs of filter 173:   944 ( 49.42s )\n",
      "Costs of filter 174:   646 ( 50.11s )\n",
      "Costs of filter 175:   480 ( 49.92s )\n",
      "Costs of filter 177:   764 ( 49.62s )\n",
      "Costs of filter 180:   421 ( 49.49s )\n",
      "Costs of filter 181:   643 ( 49.90s )\n",
      "Costs of filter 182:  1141 ( 49.22s )\n",
      "Costs of filter 183:   461 ( 48.69s )\n",
      "Costs of filter 185:   616 ( 48.49s )\n",
      "Costs of filter 186:   525 ( 48.85s )\n",
      "Costs of filter 187:   972 ( 49.63s )\n",
      "Costs of filter 188:   545 ( 49.77s )\n",
      "Costs of filter 190:   463 ( 48.74s )\n",
      "Costs of filter 192:   319 ( 48.39s )\n",
      "Costs of filter 197:   550 ( 50.42s )\n",
      "Costs of filter 201:   462 ( 51.23s )\n",
      "Costs of filter 202:   522 ( 50.72s )\n",
      "Costs of filter 203:   511 ( 50.72s )\n",
      "Costs of filter 204:   437 ( 49.62s )\n",
      "Costs of filter 206:   518 ( 48.97s )\n",
      "Costs of filter 207:   366 ( 49.51s )\n",
      "Costs of filter 208:   985 ( 49.29s )\n",
      "Costs of filter 209:   750 ( 49.53s )\n",
      "Costs of filter 212:   362 ( 49.26s )\n",
      "Costs of filter 213:   832 ( 49.48s )\n",
      "Costs of filter 214:   542 ( 49.12s )\n",
      "Costs of filter 218:   486 ( 49.16s )\n",
      "Costs of filter 219:   840 ( 48.72s )\n",
      "Costs of filter 220:   774 ( 48.95s )\n",
      "Costs of filter 221:   576 ( 51.64s )\n",
      "Costs of filter 223:   379 ( 53.52s )\n",
      "Costs of filter 224:   537 ( 53.10s )\n",
      "Costs of filter 225:   169 ( 51.79s )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 227:   438 ( 52.32s )\n",
      "Costs of filter 233:   385 ( 51.77s )\n",
      "Costs of filter 234:   697 ( 51.82s )\n",
      "Costs of filter 235:   783 ( 52.33s )\n",
      "Costs of filter 236:   563 ( 50.16s )\n",
      "Costs of filter 237:   567 ( 53.14s )\n",
      "Costs of filter 238:   591 ( 52.09s )\n",
      "Costs of filter 240:   518 ( 51.74s )\n",
      "Costs of filter 241:   699 ( 50.93s )\n",
      "Costs of filter 243:   759 ( 51.03s )\n",
      "Costs of filter 245:  1028 ( 51.58s )\n",
      "Costs of filter 246:   348 ( 53.21s )\n",
      "Costs of filter 247:   516 ( 49.59s )\n",
      "Costs of filter 249:   572 ( 50.47s )\n",
      "Costs of filter 250:  1017 ( 50.36s )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 79 of 93 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 251:   480 ( 53.58s )\n",
      "Costs of filter 255:   653 ( 54.41s )\n",
      "Costs of filter 256:   448 ( 53.82s )\n",
      "Costs of filter 257:   576 ( 50.82s )\n",
      "Costs of filter 258:   607 ( 49.20s )\n",
      "Costs of filter 262:   496 ( 48.93s )\n",
      "Costs of filter 263:   557 ( 52.42s )\n",
      "Costs of filter 264:   598 ( 51.22s )\n",
      "Costs of filter 265:   827 ( 50.46s )\n",
      "Costs of filter 267:   393 ( 50.30s )\n",
      "Costs of filter 268:   484 ( 51.64s )\n",
      "Costs of filter 269:   627 ( 49.95s )\n",
      "Costs of filter 270:  1375 ( 50.61s )\n",
      "Costs of filter 271:   603 ( 50.29s )\n",
      "Costs of filter 272:   658 ( 50.81s )\n",
      "Costs of filter 275:   546 ( 50.07s )\n",
      "Costs of filter 278:   636 ( 49.84s )\n",
      "Costs of filter 279:   662 ( 49.56s )\n",
      "Costs of filter 280:   269 ( 50.66s )\n",
      "Costs of filter 281:   579 ( 50.36s )\n",
      "Costs of filter 282:   470 ( 50.91s )\n",
      "Costs of filter 285:   613 ( 50.45s )\n",
      "Costs of filter 286:  1008 ( 62.05s )\n",
      "Costs of filter 287:   455 ( 50.78s )\n",
      "Costs of filter 289:   467 ( 49.36s )\n",
      "Costs of filter 291:   417 ( 50.06s )\n",
      "Costs of filter 293:   477 ( 50.50s )\n",
      "Costs of filter 294:   705 ( 50.10s )\n",
      "Costs of filter 295:   830 ( 49.37s )\n",
      "Costs of filter 296:   440 ( 50.01s )\n",
      "Costs of filter 297:   690 ( 49.75s )\n",
      "Costs of filter 299:   467 ( 50.34s )\n",
      "Costs of filter 300:  1026 ( 50.22s )\n",
      "Costs of filter 301:   876 ( 51.40s )\n",
      "Costs of filter 302:   940 ( 51.67s )\n",
      "Costs of filter 303:   531 ( 51.69s )\n",
      "Costs of filter 305:   456 ( 49.50s )\n",
      "Costs of filter 306:   728 ( 49.58s )\n",
      "Costs of filter 308:   727 ( 51.99s )\n",
      "Costs of filter 309:  1322 ( 51.27s )\n",
      "Costs of filter 311:   457 ( 50.79s )\n",
      "Costs of filter 320:   630 ( 52.33s )\n",
      "Costs of filter 322:   734 ( 50.92s )\n",
      "Costs of filter 323:   551 ( 49.52s )\n",
      "Costs of filter 327:   620 ( 52.70s )\n",
      "Costs of filter 328:   758 ( 49.89s )\n",
      "Costs of filter 331:   557 ( 51.03s )\n",
      "Costs of filter 332:   982 ( 50.61s )\n",
      "Costs of filter 333:   408 ( 51.10s )\n",
      "Costs of filter 334:   784 ( 50.55s )\n",
      "Costs of filter 336:   531 ( 51.14s )\n",
      "Costs of filter 338:   737 ( 50.88s )\n",
      "Costs of filter 339:   656 ( 50.70s )\n",
      "Costs of filter 341:   396 ( 50.76s )\n",
      "Costs of filter 343:   335 ( 50.51s )\n",
      "Costs of filter 345:   455 ( 47.74s )\n",
      "Costs of filter 346:   937 ( 48.17s )\n",
      "Costs of filter 348:   727 ( 47.43s )\n",
      "Costs of filter 349:   497 ( 47.01s )\n",
      "Costs of filter 352:   605 ( 47.18s )\n",
      "Costs of filter 353:   672 ( 48.47s )\n",
      "Costs of filter 356:   765 ( 49.81s )\n",
      "Costs of filter 357:   467 ( 50.08s )\n",
      "Costs of filter 359:   593 ( 49.21s )\n",
      "Costs of filter 360:   380 ( 49.62s )\n",
      "Costs of filter 361:   529 ( 48.98s )\n",
      "Costs of filter 362:   632 ( 49.03s )\n",
      "Costs of filter 365:   791 ( 49.50s )\n",
      "Costs of filter 367:   732 ( 48.82s )\n",
      "Costs of filter 368:   908 ( 49.01s )\n",
      "Costs of filter 369:   780 ( 49.80s )\n",
      "Costs of filter 371:  1198 ( 50.23s )\n",
      "Costs of filter 374:   558 ( 49.42s )\n",
      "Costs of filter 375:   571 ( 52.54s )\n",
      "Costs of filter 376:   975 ( 48.95s )\n",
      "Costs of filter 377:   628 ( 47.94s )\n",
      "Costs of filter 378:   588 ( 47.57s )\n",
      "Costs of filter 381:   521 ( 47.03s )\n",
      "Costs of filter 383:   973 ( 47.16s )\n",
      "Costs of filter 387:   681 ( 47.89s )\n",
      "Costs of filter 388:   734 ( 51.23s )\n",
      "Costs of filter 389:   477 ( 50.09s )\n",
      "Costs of filter 393:   427 ( 49.95s )\n",
      "Costs of filter 394:   593 ( 50.29s )\n",
      "Costs of filter 397:   576 ( 50.34s )\n",
      "Costs of filter 399:   796 ( 50.62s )\n",
      "Costs of filter 402:   388 ( 49.38s )\n",
      "Costs of filter 405:   704 ( 50.57s )\n",
      "Costs of filter 410:   288 ( 52.18s )\n",
      "Costs of filter 412:   821 ( 50.26s )\n",
      "Costs of filter 414:   423 ( 50.99s )\n",
      "Costs of filter 415:   970 ( 50.84s )\n",
      "Costs of filter 416:   439 ( 51.73s )\n",
      "Costs of filter 417:   681 ( 51.85s )\n",
      "Costs of filter 418:   620 ( 51.53s )\n",
      "Costs of filter 421:   521 ( 48.71s )\n",
      "Costs of filter 422:   478 ( 47.73s )\n",
      "Costs of filter 423:   749 ( 50.32s )\n",
      "Costs of filter 424:   598 ( 47.32s )\n",
      "Costs of filter 426:   495 ( 49.10s )\n",
      "Costs of filter 427:   579 ( 50.99s )\n",
      "Costs of filter 428:   697 ( 49.76s )\n",
      "Costs of filter 430:   450 ( 51.16s )\n",
      "Costs of filter 433:   650 ( 52.02s )\n",
      "Costs of filter 435:   554 ( 49.96s )\n",
      "Costs of filter 436:   808 ( 51.57s )\n",
      "Costs of filter 437:   747 ( 51.15s )\n",
      "Costs of filter 438:   659 ( 52.03s )\n",
      "Costs of filter 439:   814 ( 56.55s )\n",
      "Costs of filter 440:   877 ( 57.15s )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 79 of 93 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 79 of 93 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 442:   715 ( 60.47s )\n",
      "Costs of filter 445:   423 ( 56.33s )\n",
      "Costs of filter 446:   800 ( 56.98s )\n",
      "Costs of filter 448:   469 ( 55.24s )\n",
      "Costs of filter 449:   542 ( 56.16s )\n",
      "Costs of filter 452:   703 ( 58.34s )\n",
      "Costs of filter 453:   622 ( 58.60s )\n",
      "Costs of filter 457:   621 ( 57.18s )\n",
      "Costs of filter 458:   709 ( 55.61s )\n",
      "Costs of filter 460:   726 ( 55.28s )\n",
      "Costs of filter 461:   441 ( 53.11s )\n",
      "Costs of filter 462:   467 ( 53.96s )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 79 of 93 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 465:   494 ( 58.49s )\n",
      "Costs of filter 467:   455 ( 57.15s )\n",
      "Costs of filter 470:   426 ( 55.58s )\n",
      "Costs of filter 473:   726 ( 56.95s )\n",
      "Costs of filter 474:   437 ( 58.14s )\n",
      "Costs of filter 475:   445 ( 60.83s )\n",
      "Costs of filter 476:   520 ( 58.98s )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 86 of 93 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Costs of filter 478:   442 ( 51.10s )\n",
      "Costs of filter 481:   635 ( 50.34s )\n",
      "Costs of filter 482:   316 ( 48.91s )\n",
      "Costs of filter 483:   517 ( 51.79s )\n",
      "Costs of filter 484:   327 ( 53.29s )\n",
      "Costs of filter 485:   977 ( 50.52s )\n",
      "Costs of filter 487:   595 ( 50.52s )\n",
      "Costs of filter 489:   626 ( 51.94s )\n",
      "Costs of filter 490:   634 ( 50.24s )\n",
      "Costs of filter 493:   576 ( 52.19s )\n",
      "Costs of filter 494:   801 ( 50.55s )\n",
      "Costs of filter 495:   624 ( 53.31s )\n",
      "Costs of filter 496:   472 ( 50.43s )\n",
      "Costs of filter 499:   656 ( 51.67s )\n",
      "Costs of filter 500:   779 ( 53.74s )\n",
      "Costs of filter 501:   626 ( 54.83s )\n",
      "Costs of filter 502:   493 ( 53.40s )\n",
      "Costs of filter 503:   458 ( 50.64s )\n",
      "Costs of filter 504:   994 ( 48.24s )\n",
      "Costs of filter 505:   873 ( 50.72s )\n",
      "Costs of filter 506:   453 ( 49.25s )\n",
      "Costs of filter 509:   460 ( 52.90s )\n",
      "Costs of filter 510:   551 ( 50.58s )\n",
      "Costs of filter 511:   901 ( 49.49s )\n",
      "308 filter processed.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # the name of the layer we want to visualize\n",
    "    # (see model definition at keras/applications/vgg16.py)\n",
    "    LAYER_NAME = 'block5_conv1'\n",
    "\n",
    "    # build the VGG16 network with ImageNet weights\n",
    "    vgg = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "    print('Model loaded.')\n",
    "    vgg.summary()\n",
    "\n",
    "    # example function call\n",
    "    visualize_layer(vgg, LAYER_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
